version: '3.8'

services:
  seedvr:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: seedvr-runpod
    ports:
      - "7860:7860"
    environment:
      # Gradio configuration
      - GRADIO_SHARE=${GRADIO_SHARE:-false}
      - GRADIO_PORT=${GRADIO_PORT:-7860}
      - GRADIO_HOST=${GRADIO_HOST:-0.0.0.0}
      
      # HuggingFace token (required for model downloads)
      - HF_TOKEN=${HF_TOKEN}
      
      # CUDA configuration
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      
      # PyTorch distributed settings
      - RANK=0
      - LOCAL_RANK=0
      - WORLD_SIZE=1
      - NNODES=1
    
    volumes:
      # Persistent storage for models and cache
      - ./data/ckpts:/workspace/ckpts
      - ./data/cache:/workspace/cache
      - ./data/outputs:/workspace/outputs
      - ./data/temp:/workspace/temp
    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    restart: unless-stopped
    
    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7860"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 300s  # Allow time for model downloads

volumes:
  seedvr_data:
    driver: local